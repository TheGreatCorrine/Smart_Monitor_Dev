#!/usr/bin/env python3
"""
tests/integration/test_parse_dat.py
------------------------------------
æµ‹è¯• dat_parser.py çš„åŠŸèƒ½
ä½¿ç”¨ MPL6.dat æ–‡ä»¶å¹¶ç»“æ„åŒ–æ‰“å°ç»“æœ
"""
import sys
from pathlib import Path

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„ï¼Œæ–¹ä¾¿IDEç›´æ¥è¿è¡Œ
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "backend"))

import json
from datetime import datetime

from app.infra.datastore.DatParser import iter_new_records


def test_parse_mpl6_dat():
    """æµ‹è¯•è§£æ MPL6.dat æ–‡ä»¶"""
    dat_file = Path("MPL6.dat")
    
    if not dat_file.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {dat_file}")
        return
    
    print(f"ğŸ” å¼€å§‹è§£ææ–‡ä»¶: {dat_file}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {dat_file.stat().st_size:,} bytes")
    print("-" * 60)
    
    # è§£æè®°å½•
    records = []
    try:
        for record in iter_new_records(dat_file, run_id="TEST_MPL6"):
            records.append(record)
            
            # åªæ˜¾ç¤ºå‰5æ¡è®°å½•ç”¨äºé¢„è§ˆ
            if len(records) <= 5:
                print(f"ğŸ“ è®°å½• #{len(records)}:")
                print(f"   Run ID: {record.run_id}")
                print(f"   æ—¶é—´æˆ³: {record.ts}")
                print(f"   æ–‡ä»¶ä½ç½®: {record.file_pos:,} bytes")
                print(f"   é€šé“æ•°é‡: {len(record.metrics)}")
                
                # æ˜¾ç¤ºå‰10ä¸ªé€šé“çš„å€¼
                print("   é€šé“æ•°æ®:")
                for i, (channel, value) in enumerate(record.metrics.items()):
                    if i >= 10:  # åªæ˜¾ç¤ºå‰10ä¸ª
                        print(f"     ... è¿˜æœ‰ {len(record.metrics) - 10} ä¸ªé€šé“")
                        break
                    print(f"     {channel}: {value}")
                print()
        
        print("-" * 60)
        print(f"âœ… è§£æå®Œæˆ!")
        print(f"ğŸ“ˆ æ€»è®°å½•æ•°: {len(records)}")
        
        if records:
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            first_record = records[0]
            last_record = records[-1]
            
            print(f"â° æ—¶é—´èŒƒå›´:")
            print(f"   å¼€å§‹: {first_record.ts}")
            print(f"   ç»“æŸ: {last_record.ts}")
            
            # è®¡ç®—æ—¶é—´é—´éš”
            time_diff = last_record.ts - first_record.ts
            print(f"   æ€»æ—¶é•¿: {time_diff}")
            
            # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„é€šé“
            print(f"ğŸ”§ å¯ç”¨é€šé“ ({len(first_record.metrics)} ä¸ª):")
            channels = sorted(first_record.metrics.keys())
            for i, channel in enumerate(channels):
                if i % 8 == 0:  # æ¯è¡Œ8ä¸ª
                    print("   ", end="")
                print(f"{channel:>8}", end="")
                if (i + 1) % 8 == 0 or i == len(channels) - 1:
                    print()
            
            # æ˜¾ç¤ºä¸€äº›æ•°å€¼ç»Ÿè®¡
            print(f"ğŸ“Š æ•°å€¼ç»Ÿè®¡ (ç¬¬ä¸€æ¡è®°å½•):")
            numeric_channels = [k for k, v in first_record.metrics.items() 
                              if isinstance(v, (int, float)) and not isinstance(v, bool)]
            if numeric_channels:
                print(f"   æ•°å€¼é€šé“: {len(numeric_channels)} ä¸ª")
                for channel in numeric_channels[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                    value = first_record.metrics[channel]
                    print(f"   {channel}: {value}")
                if len(numeric_channels) > 5:
                    print(f"   ... è¿˜æœ‰ {len(numeric_channels) - 5} ä¸ªæ•°å€¼é€šé“")
            
            # æ˜¾ç¤ºå¸ƒå°”é€šé“
            bool_channels = [k for k, v in first_record.metrics.items() 
                           if isinstance(v, bool)]
            if bool_channels:
                print(f"   å¸ƒå°”é€šé“: {len(bool_channels)} ä¸ª")
                for channel in bool_channels[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                    value = first_record.metrics[channel]
                    print(f"   {channel}: {value}")
                if len(bool_channels) > 5:
                    print(f"   ... è¿˜æœ‰ {len(bool_channels) - 5} ä¸ªå¸ƒå°”é€šé“")
        
    except Exception as e:
        print(f"âŒ è§£æé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def test_record_structure():
    """æµ‹è¯•Recordç»“æ„"""
    print("\n" + "=" * 60)
    print("ğŸ”¬ æµ‹è¯•Recordç»“æ„")
    print("=" * 60)
    
    dat_file = Path("MPL6.dat")
    if not dat_file.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {dat_file}")
        return
    
    # è·å–ç¬¬ä¸€æ¡è®°å½•
    for record in iter_new_records(dat_file, run_id="STRUCTURE_TEST"):
        print(f"ğŸ“‹ Record ç»“æ„åˆ†æ:")
        print(f"   ç±»å‹: {type(record)}")
        print(f"   å±æ€§: {list(record.__dataclass_fields__.keys())}")
        print(f"   æ˜¯å¦ä¸å¯å˜: {hasattr(record, '__hash__')}")
        print(f"   æ˜¯å¦ä½¿ç”¨slots: {hasattr(record, '__slots__')}")
        
        # æµ‹è¯•to_dictæ–¹æ³•
        record_dict = record.to_dict()
        print(f"   to_dict() é”®: {list(record_dict.keys())[:10]}...")
        
        # æµ‹è¯•getæ–¹æ³•
        if record.metrics:
            first_key = list(record.metrics.keys())[0]
            value = record.get(first_key)
            print(f"   get('{first_key}'): {value}")
        
        break  # åªæµ‹è¯•ç¬¬ä¸€æ¡è®°å½•


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯• dat_parser.py")
    print("=" * 60)
    
    test_parse_mpl6_dat()
    test_record_structure()
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ!") 